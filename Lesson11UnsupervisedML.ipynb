{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson11UnsupervisedML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbechara/HertieML/blob/main/Lesson11UnsupervisedML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6bClBSlnLz2"
      },
      "source": [
        "*Exercise: The classic Olivetti faces dataset contains 400 grayscale 64 × 64–pixel images of faces. Each image is flattened to a 1D vector of size 4,096. 40 different people were photographed (10 times each), and the usual task is to train a model that can predict which person is represented in each picture. Load the dataset using the `sklearn.datasets.fetch_olivetti_faces()` function.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO0NnqLPnaIY"
      },
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "olivetti = fetch_olivetti_faces()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4ZfmO8wo4J7"
      },
      "source": [
        "Split it into a training set, a validation set, and a test set (note that the dataset is already scaled between 0 and 1). \n",
        "\n",
        "Tip: Use stratified sampling to ensure that there are the same number of images per person in each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEAsgU3yo-s0"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=40, random_state=42)\n",
        "train_valid_idx, test_idx = next(strat_split.split(olivetti.data, olivetti.target))\n",
        "X_train_valid = olivetti.data[train_valid_idx]\n",
        "y_train_valid = olivetti.target[train_valid_idx]\n",
        "X_test = olivetti.data[test_idx]\n",
        "y_test = olivetti.target[test_idx]\n",
        "\n",
        "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=80, random_state=42)\n",
        "train_idx, valid_idx = next(strat_split.split(X_train_valid, y_train_valid))\n",
        "X_train = X_train_valid[train_idx]\n",
        "y_train = y_train_valid[train_idx]\n",
        "X_valid = X_train_valid[valid_idx]\n",
        "y_valid = y_train_valid[valid_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLbCZfPtpIpU"
      },
      "source": [
        "Reduce the data's dimensionality using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBPR4kdopLU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3126ff9f-ff50-491e-c2e6-95edf4ad71bf"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 0.99)\n",
        "oli_reduced_data = pca.fit_transform(olivetti.data)\n",
        "\n",
        "pca.n_components_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "260"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2haVkmnvXOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271a034a-5b13-4241-814f-956ce781051f"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=40, random_state=42)\n",
        "\n",
        "\n",
        "for train_valid_index, test_index in sss.split(olivetti.data, olivetti.target):\n",
        "  print(\"TRAIN_VALID:\", train_valid_index, \"TEST:\", test_index)\n",
        "  oli_train_valid = oli_reduced_data[train_valid_index]\n",
        "  oli_labels_train_valid = olivetti.target[train_valid_index]\n",
        "  oli_test = oli_reduced_data[test_index]\n",
        "  oli_labels_test = olivetti.target[test_index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN_VALID: [236 330 109 369 251  60  63 288  95 262  65 276 213  86 261 302 337 345\n",
            " 105 340 216 245 317 167 184 134  77 296 305 274 263  94 351  14 121 311\n",
            "  74 112 116  88 158  11 358 282 380 283  38  70 204 395 290 250 334 399\n",
            " 336 287   5 232 144  40  82 202 145 346 364 187  87 267 222 131 227 326\n",
            "  64 398  32  72 175 237  42  79 106 275 367 143  45 393 207 316  71  21\n",
            "  53 177 344  48 165 215   9 252 224 235 189 156 374 180 342  93 196 313\n",
            " 249  13 383 181  47 329 123 256  62 234 163 327 151 259 130 142  23 388\n",
            " 335 239 293 124  92  59 223  31   3 272 244  29 266 125 229  61 324 394\n",
            "  36 200 225 242 349 128 386 389 365 303 231 348 381 226 281 233  20 301\n",
            " 172  84 366 298 149 117 129 170 199 271 273   4  99  81  34 148 396 387\n",
            " 280 155 268  43  46  80 185 310  78  73  18 378 186 279 286 373 240 300\n",
            " 188 193 157 162  97 174 371   1  85  25  17   0 321 294 291 339 308 153\n",
            " 322  33 253 260  10  28 323 241  30 111 353  90 357 372 246 356 228 214\n",
            " 355 103 314 377 397 221  37 208  96 325 195 376 171  89 212 359 107  26\n",
            "  75 379 211 255 206 264  98  55 132 138 108 269   8 137 304 141 361 120\n",
            " 257 328 347 135 164 168 392 119 139 297 150  52 295 210 114   7 118  67\n",
            "  50 341 115 363 306 350 194 360 161 133 217  68 205 169  51 238 362 102\n",
            " 159 154 299  22 192  35  15 333  27 278 182  44 197 270 331 113 309 178\n",
            " 147 160 312 126 384 191 375  66  54 248 315  16 140 354 289 173 284 219\n",
            " 127 203 391 100 201 338 382 318  41 258 101   2  58 179 243 190  19  57] TEST: [ 39  76 254 152  69  24 136 370 319 209 110 390 332  83 265 220 104 166\n",
            " 292 368 218   6 307 352 320 230  91  12 247 146  49 183 176  56 343 385\n",
            " 285 277 122 198]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raa18HGbvYMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cad776f-b1d4-4930-fcd4-7b18fe1479be"
      },
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=80, random_state=42)\n",
        "for train_index, valid_index in sss.split(oli_train_valid, oli_labels_train_valid):\n",
        "  print(\"TRAIN:\", train_index, \"VALID:\", test_index)\n",
        "  oli_train = oli_train_valid[train_index]\n",
        "  oli_labels_train = oli_labels_train_valid[train_index]\n",
        "  oli_valid = oli_train_valid[valid_index]\n",
        "  oli_labels_valid = oli_labels_train_valid[valid_index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [127  80  24  10 163  12 182 183  37 293 131  53   0 215 358 277 102  77\n",
            " 177 159  18 275 144 330  44 305 272 166  17 250  41 271  90 160  52  79\n",
            " 190 171 205 269  58 225 255  81  57 120 143 139 117   2 104 112  98  95\n",
            " 191 141 320 321 281 238 290 209 352 148  50 211 325 167  35  82 180 208\n",
            " 310  51  96 334 179 229 256  91 198 257 129 213 165 245 220 106 348 194\n",
            " 114 216   7 199 339 200  40  27 279 254 138 346 284  78   3  45 154 351\n",
            " 193  43 235  32  63 125 242 219 105 239 206 137 103 329 232 308 168 299\n",
            " 274 246 278 317 285 169 294  65 153 240 185 234 327 230   4 309 151 203\n",
            " 145 306 249 197 276   9  36  47  55  72 261 126 181 231 336 353 101  15\n",
            " 189  30 324 107 314 130 268 121  64 187  20 162 175 340 237 266 161 227\n",
            " 297 260 241 201  48  61  33   8 221 136 354  60  85 247 335 283 233 252\n",
            "  16 311 333 359 328   5 244 142 295 152 186  70 316  29 298 149 196 350\n",
            "  94 289  21 123 210  13  26  87 133 251 344 174 178  28 146 322 172 301\n",
            "  71  14 226 265 115  42  92  69 224 259  54  76  83 134 296 287 236 110\n",
            " 326 108  89 291 116 135 184  56 343 273 243  46 253  88 222 302 140 313\n",
            "  74  97  59 111 319 170 202  68 147 128] VALID: [ 39  76 254 152  69  24 136 370 319 209 110 390 332  83 265 220 104 166\n",
            " 292 368 218   6 307 352 320 230  91  12 247 146  49 183 176  56 343 385\n",
            " 285 277 122 198]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i0OcGnBp52s"
      },
      "source": [
        " Cluster the images using K-Means, and ensure that you have a good number of clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miiUXJaMqCK9"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_range = range(5, 150, 5)\n",
        "kmeans_per_k = []\n",
        "for k in k_range:\n",
        "    print(\"k={}\".format(k))\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42).fit(oli_train)\n",
        "    kmeans_per_k.append(kmeans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUqemUyDqOGC"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "silhouette_scores = [silhouette_score(oli_train, model.labels_) for model in kmeans_per_k]\n",
        "best_index = np.argmax(silhouette_scores)\n",
        "best_k = k_range[best_index]\n",
        "print(\"Best k = {}\".format(best_k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r87j1dQV3J-e"
      },
      "source": [
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(k_range, silhouette_scores, \"bo-\")\n",
        "plt.xlabel(\"$k$\", fontsize=14)\n",
        "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
        "plt.plot(best_k, best_score, \"rs\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gvNNwlsM8Jm"
      },
      "source": [
        "What is the best k for this dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vSOLqQiMgdk"
      },
      "source": [
        "As a baseline, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set.\n",
        "\n",
        "To keep Slava happy, we will make it a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JX4XQ4NR1v"
      },
      "source": [
        "# Thilos solution\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf_RF = RandomForestClassifier(random_state=42)\n",
        "clf_RF.fit(oli_train, oli_labels_train)\n",
        "y_valid_predict = clf_RF.predict(oli_valid)\n",
        "accuracy_score(oli_labels_valid, y_valid_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVrFLlPW5JxQ"
      },
      "source": [
        "for k in range(len(k_range)):\n",
        "  if k_range[k] == 105:\n",
        "    print(k)\n",
        "    index_105 = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1cMtPfU5LmE"
      },
      "source": [
        "best_model = kmeans_per_k[index_105]\n",
        "oli_train_best = best_model.transform(oli_train)\n",
        "oli_valid_best = best_model.transform(oli_valid)\n",
        "oli_test_best = best_model.transform(oli_test)\n",
        "\n",
        "clf_RF2 = RandomForestClassifier(random_state=42)\n",
        "clf_RF2.fit(oli_train_best, oli_labels_train)\n",
        "y_valid_predict = clf_RF2.predict(oli_valid_best)\n",
        "accuracy_score(oli_labels_valid, y_valid_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU3PaaPONWs3"
      },
      "source": [
        "Let's use K-Means as a dimensionality reduction tool, and train a classifier on the reduced set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbl734seOHk1"
      },
      "source": [
        "Do this for an index of 100 first. Then try a few more to see if you can get a higher score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUtfgNJhNcWt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbhZPvr5nLz6"
      },
      "source": [
        "Finally, append the features from the reduced set to the original features and see if you can beat the baseline."
      ]
    }
  ]
}